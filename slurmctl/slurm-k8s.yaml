kind: ConfigMap
apiVersion: v1
metadata:
  labels:
    k8s-app: slurm
  name: slurm-fs
data:
  # Configuration values can be set as key-value properties
  slurm.conf: |
    #
    # RPi cluster slurm.conf file.
    #
    ClusterName=rpicluster
    ControlMachine=node09
    #SlurmUser=slurm
    SlurmdUser=root
    SlurmctldPort=6817
    SlurmdPort=6818
    CryptoType=crypto/munge
    AuthType=auth/munge
    StateSaveLocation=/var/spool/slurmctld
    SlurmdSpoolDir=/var/spool/slurmctld
    SwitchType=switch/none
    MpiDefault=none
    SlurmctldPidFile=/var/run/slurmctld.pid
    SlurmdPidFile=/var/run/slurmd.pid
    ProctrackType=proctrack/pgid
    ReturnToService=0
    SlurmctldTimeout=300
    SlurmdTimeout=300
    InactiveLimit=0
    MinJobAge=300
    KillWait=30
    Waittime=0
    SchedulerType=sched/backfill
    FastSchedule=1
    SlurmctldDebug=3
    SlurmctldLogFile=/var/log/supervisor/slurmctld.log
    SlurmdDebug=3
    SlurmdLogFile=/var/log/supervisor/slurmd.log
    JobCompType=jobcomp/none
    # COMPUTE NODES
    # node [02-05] living in RPi cluster
    NodeName=node02 NodeAddr=10.0.0.3 CPUs=4 State=UNKNOWN
    NodeName=node03 NodeAddr=10.0.0.4 CPUs=1 State=UNKNOWN
    NodeName=node04 NodeAddr=10.0.0.5 CPUs=1 State=UNKNOWN
    NodeName=node05 NodeAddr=10.0.0.6 CPUs=4 State=UNKNOWN
    PartitionName=allnodes Nodes=node[02-05] Default=YES MaxTime=INFINITE State=UP

  cgroup_allowed_devices_file.conf: |
    /dev/null
    /dev/urandom
    /dev/zero
    /dev/sda*
    /dev/cpu/*/*
    /dev/pts/*
    /clusterfs*

  cgroup.conf: |
    CgroupMountpoint="/sys/fs/cgroup"
    CgroupAutomount=yes
    CgroupReleaseAgentDir="/usr/local/etc/cgroup"
    AllowedDevicesFile="/usr/local/etc/cgroup_allowed_devices_file.conf"
    ConstrainCores=no
    TaskAffinity=no
    ConstrainRAMSpace=yes
    ConstrainSwapSpace=no
    ConstrainDevices=no
    AllowedRamSpace=100
    AllowedSwapSpace=0
    MaxRAMPercent=100
    MaxSwapPercent=100
    MinRAMSpace=30

---
kind: ConfigMap
apiVersion: v1
metadata:
  labels:
    k8s-app: slurm
  name: slurm-config
data:
  # Configuration values can be set as key-value properties
  nfs_server: node01.home.lab
  nfs_mount: /clusterfs
  subPath: clustershare/

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: slurm
spec:
  selector:
    matchLabels:
      app: slurm
  replicas: 1
  strategy: {}
  template:
    metadata:
      labels:
        app: slurm
      annotations:
        prometheus.io/scrape: "true"
    spec:
      hostAliases:
      - ip: "10.0.0.9"
        hostnames:
        - "node09"
        - "node09.home.lab"
      - ip: "10.0.0.3"
        hostnames:
        - "node02"
        - "node02.home.lab"
      - ip: "10.0.0.4"
        hostnames:
        - "node03"
        - "node03.home.lab"
      - ip: "10.0.0.5"
        hostnames:
        - "node04"
        - "node04.home.lab"
      - ip: "10.0.0.6"
        hostnames:
        - "node05"
        - "node05.home.lab"
      containers:
      - name: slurm
        image: strusfr/docker-ubuntu1604-slurmctld:latest
        imagePullPolicy: Alwyas
        stdin: true
        tty: true
        resources:
          limits:
            cpu: 200m
            memory: 64Mi
          requests:
            cpu: 200m
            memory: 64Mi
        env:
          - name: SLURM_CLUSTER_NAME
            value: rpicluster
          - name: SLURM_CONTROL_MACHINE
            value: node09
          - name: SLURM_NODE_NAMES
            value: node[02-05]
          - name: MY_POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
        volumeMounts:
        - name: config-volume
          mountPath: /usr/local/etc/slurm.conf
          subPath: slurm.conf
        - name: config-volume
          mountPath: /usr/local/etc/cgroup_allowed_devices_file.conf
          subPath: cgroup_allowed_devices_file.conf
        - name: config-volume
          mountPath: /usr/local/etc/cgroup.conf
          subPath: cgroup.conf
        - name: nfs-volume
          mountPath: /clusterfs
        lifecycle:
          postStart:
            exec:
              command: ["/bin/sh", "-c", "cp /etc/munge/munge.key /clusterfs/munge.key"]
      hostname: node09
      restartPolicy: Always
      volumes:
      - name: config-volume
        configMap:
            name: slurm-fs
      - name: nfs-volume
        nfs: 
          # URL for the NFS server
          server: node01.home.lab # Change this!
          path: /clusterfs

---
apiVersion: v1
kind: Service
metadata:
  name: slurmctld
  annotations:
    prometheus.io/scrape: "true"
spec:
  selector:
    app: slurm
  ports:
    - name: tcp6817
      protocol: TCP
      port: 6817
      targetPort: 6817
    - name: tcp6818
      protocol: TCP
      port: 6818
      targetPort: 6818
    - name: tcp22
      protocol: TCP
      port: 22
      targetPort: 22
    - name: tcp8080
      protocol: TCP
      port: 8080
      targetPort: 8080
  type: LoadBalancer
  loadBalancerIP: 10.0.0.9